{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMN7pVUawzEmq2tQ3VhxxSg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a52231-oss/NLP/blob/main/2403a52231_Assi_8_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jTUxhThoR0k3"
      },
      "outputs": [],
      "source": [
        "Doc1 = \"The cat sat on the mat.\"\n",
        "Doc2 = \"Dogs are loyal and friendly animals.\"\n",
        "Doc3 = \"Artificial intelligence is transforming industries.\"\n",
        "Doc4 = \"Stock prices can be predicted using machine learning.\"\n",
        "Doc5 = \"Patents protect innovative ideas and inventions.\"\n",
        "Doc6 = \"Data science combines statistics with programming.\"\n",
        "Doc7 = \"Natural language processing helps computers understand text.\"\n",
        "Doc8 = \"Renewable energy sources are vital for a sustainable future.\"\n",
        "Doc9 = \"Neural networks are inspired by the human brain.\"\n",
        "Doc10 = \"Cybersecurity protects systems from digital threats.\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unigram counts"
      ],
      "metadata": {
        "id": "oafaUDvBTpGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "Doc1 = \"The cat sat on the mat.\"\n",
        "Doc2 = \"Dogs are loyal and friendly animals.\"\n",
        "Doc3 = \"Artificial intelligence is transforming industries.\"\n",
        "Doc4 = \"Stock prices can be predicted using machine learning.\"\n",
        "Doc5 = \"Patents protect innovative ideas and inventions.\"\n",
        "Doc6 = \"Data science combines statistics with programming.\"\n",
        "Doc7 = \"Natural language processing helps computers understand text.\"\n",
        "Doc8 = \"Renewable energy sources are vital for a sustainable future.\"\n",
        "Doc9 = \"Neural networks are inspired by the human brain.\"\n",
        "Doc10 = \"Cybersecurity protects systems from digital threats.\"\n",
        "\n",
        "# Assign content of text cells to Python variables\n",
        "D1_content = \"The cat sat on the mat.\"\n",
        "D2_content = \"Dogs are loyal and friendly animals.\"\n",
        "D3_content = \"Artificial intelligence is transforming industries.\"\n",
        "D4_content = \"Stock prices can be predicted using machine learning.\"\n",
        "D5_content = \"Patents protect innovative ideas and inventions.\"\n",
        "D6_content = \"Data science combines statistics with programming.\"\n",
        "D7_content = \"Natural language processing helps computers understand text.\"\n",
        "D8_content = \"Renewable energy sources are vital for a sustainable future.\"\n",
        "D9_content = \"Neural networks are inspired by the human brain.\"\n",
        "D10_content = \"Cybersecurity protects systems from digital threats.\"\n",
        "\n",
        "# Combine the text from D1, D2, D3, D4 (using the newly defined content variables)\n",
        "combined_text = f\"{D1_content} {D2_content} {D3_content} {D4_content}\"\n",
        "\n",
        "# Tokenize the combined text into words and convert to lowercase\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Calculate unigram counts\n",
        "unigram_counts = collections.Counter(words)\n",
        "\n",
        "# Print the unigram counts\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in unigram_counts.most_common():\n",
        "    print(f\"{word}: {count}\")\n",
        "#Vocabulary size is length of unigrams\n",
        "V=len(unigram_counts)\n",
        "print(\"Vocabulary Size=\",V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EQwEFNBO8HW",
        "outputId": "46e041bf-eee9-4897-b7e0-befd1ae61c88"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "the: 2\n",
            "cat: 1\n",
            "sat: 1\n",
            "on: 1\n",
            "mat.: 1\n",
            "dogs: 1\n",
            "are: 1\n",
            "loyal: 1\n",
            "and: 1\n",
            "friendly: 1\n",
            "animals.: 1\n",
            "artificial: 1\n",
            "intelligence: 1\n",
            "is: 1\n",
            "transforming: 1\n",
            "industries.: 1\n",
            "stock: 1\n",
            "prices: 1\n",
            "can: 1\n",
            "be: 1\n",
            "predicted: 1\n",
            "using: 1\n",
            "machine: 1\n",
            "learning.: 1\n",
            "Vocabulary Size= 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bi-Gram Counts"
      ],
      "metadata": {
        "id": "omlL6yw7R9c-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "\n",
        "combined_text = f\"{D1_content} {D2_content} {D3_content} {D4_content} {D5_content} {D6_content} {D7_content} {D8_content} {D9_content} {D10_content}\"\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Generate bigrams\n",
        "bigrams = []\n",
        "for i in range(len(words) - 1):\n",
        "    bigrams.append((words[i], words[i+1]))\n",
        "\n",
        "# Calculate bigram counts\n",
        "bigram_counts = collections.Counter(bigrams)\n",
        "\n",
        "# Print the bigram counts\n",
        "print(\"\\nBigram Counts:\")\n",
        "for bigram, count in bigram_counts.most_common():\n",
        "    print(f\"{bigram[0]} {bigram[1]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baVjLSUfR7Jp",
        "outputId": "741a4874-d886-41ce-f69f-7a63aa9beab0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigram Counts:\n",
            "the cat: 1\n",
            "cat sat: 1\n",
            "sat on: 1\n",
            "on the: 1\n",
            "the mat.: 1\n",
            "mat. dogs: 1\n",
            "dogs are: 1\n",
            "are loyal: 1\n",
            "loyal and: 1\n",
            "and friendly: 1\n",
            "friendly animals.: 1\n",
            "animals. artificial: 1\n",
            "artificial intelligence: 1\n",
            "intelligence is: 1\n",
            "is transforming: 1\n",
            "transforming industries.: 1\n",
            "industries. stock: 1\n",
            "stock prices: 1\n",
            "prices can: 1\n",
            "can be: 1\n",
            "be predicted: 1\n",
            "predicted using: 1\n",
            "using machine: 1\n",
            "machine learning.: 1\n",
            "learning. patents: 1\n",
            "patents protect: 1\n",
            "protect innovative: 1\n",
            "innovative ideas: 1\n",
            "ideas and: 1\n",
            "and inventions.: 1\n",
            "inventions. data: 1\n",
            "data science: 1\n",
            "science combines: 1\n",
            "combines statistics: 1\n",
            "statistics with: 1\n",
            "with programming.: 1\n",
            "programming. natural: 1\n",
            "natural language: 1\n",
            "language processing: 1\n",
            "processing helps: 1\n",
            "helps computers: 1\n",
            "computers understand: 1\n",
            "understand text.: 1\n",
            "text. renewable: 1\n",
            "renewable energy: 1\n",
            "energy sources: 1\n",
            "sources are: 1\n",
            "are vital: 1\n",
            "vital for: 1\n",
            "for a: 1\n",
            "a sustainable: 1\n",
            "sustainable future.: 1\n",
            "future. neural: 1\n",
            "neural networks: 1\n",
            "networks are: 1\n",
            "are inspired: 1\n",
            "inspired by: 1\n",
            "by the: 1\n",
            "the human: 1\n",
            "human brain.: 1\n",
            "brain. cybersecurity: 1\n",
            "cybersecurity protects: 1\n",
            "protects systems: 1\n",
            "systems from: 1\n",
            "from digital: 1\n",
            "digital threats.: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tri-Gram Counts"
      ],
      "metadata": {
        "id": "bHEjuiL-SW9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "\n",
        "combined_text = f\"{D1_content} {D2_content} {D3_content} {D4_content} {D5_content} {D6_content} {D7_content} {D8_content} {D9_content} {D10_content}\"\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Generate bigrams\n",
        "Trigrams = []\n",
        "for i in range(len(words) - 2):\n",
        "    Trigrams.append((words[i], words[i+1], words[i+2]))\n",
        "\n",
        "# Calculate bigram counts\n",
        "Trigrams_counts = collections.Counter(Trigrams)\n",
        "\n",
        "# Print the bigram counts\n",
        "print(\"\\nTrigrams Counts:\")\n",
        "for Trigrams, count in Trigrams_counts.most_common():\n",
        "    print(f\"{Trigrams[0]} {Trigrams[1]} {Trigrams[2]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgeNXauSSYk2",
        "outputId": "c2bc1017-4152-48cf-f94a-f5a827ae81ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trigrams Counts:\n",
            "the cat sat: 1\n",
            "cat sat on: 1\n",
            "sat on the: 1\n",
            "on the mat.: 1\n",
            "the mat. dogs: 1\n",
            "mat. dogs are: 1\n",
            "dogs are loyal: 1\n",
            "are loyal and: 1\n",
            "loyal and friendly: 1\n",
            "and friendly animals.: 1\n",
            "friendly animals. artificial: 1\n",
            "animals. artificial intelligence: 1\n",
            "artificial intelligence is: 1\n",
            "intelligence is transforming: 1\n",
            "is transforming industries.: 1\n",
            "transforming industries. stock: 1\n",
            "industries. stock prices: 1\n",
            "stock prices can: 1\n",
            "prices can be: 1\n",
            "can be predicted: 1\n",
            "be predicted using: 1\n",
            "predicted using machine: 1\n",
            "using machine learning.: 1\n",
            "machine learning. patents: 1\n",
            "learning. patents protect: 1\n",
            "patents protect innovative: 1\n",
            "protect innovative ideas: 1\n",
            "innovative ideas and: 1\n",
            "ideas and inventions.: 1\n",
            "and inventions. data: 1\n",
            "inventions. data science: 1\n",
            "data science combines: 1\n",
            "science combines statistics: 1\n",
            "combines statistics with: 1\n",
            "statistics with programming.: 1\n",
            "with programming. natural: 1\n",
            "programming. natural language: 1\n",
            "natural language processing: 1\n",
            "language processing helps: 1\n",
            "processing helps computers: 1\n",
            "helps computers understand: 1\n",
            "computers understand text.: 1\n",
            "understand text. renewable: 1\n",
            "text. renewable energy: 1\n",
            "renewable energy sources: 1\n",
            "energy sources are: 1\n",
            "sources are vital: 1\n",
            "are vital for: 1\n",
            "vital for a: 1\n",
            "for a sustainable: 1\n",
            "a sustainable future.: 1\n",
            "sustainable future. neural: 1\n",
            "future. neural networks: 1\n",
            "neural networks are: 1\n",
            "networks are inspired: 1\n",
            "are inspired by: 1\n",
            "inspired by the: 1\n",
            "by the human: 1\n",
            "the human brain.: 1\n",
            "human brain. cybersecurity: 1\n",
            "brain. cybersecurity protects: 1\n",
            "cybersecurity protects systems: 1\n",
            "protects systems from: 1\n",
            "systems from digital: 1\n",
            "from digital threats.: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram Counts"
      ],
      "metadata": {
        "id": "RXmowjKiSm08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram(word_sequence, bigram_counts, unigram_counts):\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = bigram_count / last_word_unigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"the cat\"\n",
        "next_word1 = predict_next_word_bigram(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"sat on\"\n",
        "next_word2 = predict_next_word_bigram(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"computers understand\"\n",
        "next_word3 = predict_next_word_bigram(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"loyal and\"\n",
        "next_word4 = predict_next_word_bigram(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBbuU3KFSjjd",
        "outputId": "bd21bd35-a3ae-4d30-e655-1b1932a39689"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  sat is  1.0\n",
            "Given sequence: 'the cat', predicted next word: 'sat'\n",
            "probability of  the is  1.0\n",
            "Given sequence: 'sat on', predicted next word: 'the'\n",
            "Given sequence: 'computers understand', predicted next word: ''understand' not found in unigram counts. Cannot predict next word.'\n",
            "probability of  friendly is  1.0\n",
            "probability of  inventions. is  1.0\n",
            "Given sequence: 'loyal and', predicted next word: 'friendly'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Bi-Gram Model"
      ],
      "metadata": {
        "id": "e7dB0uC3S_Bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FluXUzOTAPW",
        "outputId": "7d8252d9-c9e7-431d-ed3b-6a9099f468ce"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textsat on\n",
            "probability of  the is  1.0\n",
            "Given sequence: 'sat on', predicted next word: 'the'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Tri-Gram Counts\n"
      ],
      "metadata": {
        "id": "cK0R7H6pUWWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = trigram_count / last_two_words_bigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"the cat sat\"\n",
        "next_word1 = predict_next_word_trigram(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"sat on the\"\n",
        "next_word2 = predict_next_word_trigram(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq5ogk41UKXl",
        "outputId": "0f3b1c3b-a4e1-46ae-8460-e20752c419b7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  on is  1.0\n",
            "Given sequence: 'the cat sat', predicted next word: 'on'\n",
            "probability of  mat. is  1.0\n",
            "Given sequence: 'sat on the', predicted next word: 'mat.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Tri-Gram Model"
      ],
      "metadata": {
        "id": "jiAkoHJ6VCXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mVdZ0WWVGaZ",
        "outputId": "67c44b81-b7d2-4668-f90b-0def7ee44080"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textthe cat\n",
            "probability of  sat is  1.0\n",
            "Given sequence: 'the cat', predicted next word: 'sat'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram Counts with Laplace Smoothening"
      ],
      "metadata": {
        "id": "l4f_cCUIVNzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_Laplace(word_sequence, bigram_counts, unigram_counts):\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+1) / (last_word_unigram_count+V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"the cat\"\n",
        "next_word1 = predict_next_word_bigram_Laplace(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"sat on\"\n",
        "next_word2 = predict_next_word_bigram_Laplace(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"computers understand\"\n",
        "next_word3 = predict_next_word_bigram_Laplace(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"loyal and\"\n",
        "next_word4 = predict_next_word_bigram_Laplace(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr4yi1A0VPIR",
        "outputId": "e76af717-4ca8-496e-dbc2-dea7512a0ac9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of sat is  0.08\n",
            "Given sequence: 'the cat', predicted next word: 'sat'\n",
            "probability of the is  0.08\n",
            "Given sequence: 'sat on', predicted next word: 'the'\n",
            "Given sequence: 'computers understand', predicted next word: ''understand' not found in unigram counts. Cannot predict next word.'\n",
            "probability of friendly is  0.08\n",
            "probability of inventions. is  0.08\n",
            "Given sequence: 'loyal and', predicted next word: 'friendly'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Laplace Smoothening based Bi-Gram Model"
      ],
      "metadata": {
        "id": "DMv4SpwvVeXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_Laplace(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJmFYooLVfhQ",
        "outputId": "79f5a63c-2f97-4970-b8e5-7becd9f5e93e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textloyal and\n",
            "probability of friendly is  0.08\n",
            "probability of inventions. is  0.08\n",
            "Given sequence: 'loyal and', predicted next word: 'friendly'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram Counts with Add - K Smoothening\n"
      ],
      "metadata": {
        "id": "VRMcZPDJWStQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_Laplace(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+1) / (last_two_words_bigram_count+V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"the cat sat\"\n",
        "next_word1 = predict_next_word_trigram_Laplace(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"sat on the\"\n",
        "next_word2 = predict_next_word_trigram_Laplace(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DJ6mMRNWXI_",
        "outputId": "3d7fb2e3-02d2-412c-f372-5213ed628bd9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  on is  0.08\n",
            "Given sequence: 'the cat sat', predicted next word: 'on'\n",
            "probability of  mat. is  0.08\n",
            "Given sequence: 'sat on the', predicted next word: 'mat.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Laplace Smoothening based tri-Gram Model"
      ],
      "metadata": {
        "id": "YnFKfpd7hGHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_Laplace(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6brPRJ80hHV9",
        "outputId": "ecd4e915-a876-4feb-e3e0-5cb000ee22d5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textsat on the\n",
            "probability of  mat. is  0.08\n",
            "Given sequence: 'sat on the', predicted next word: 'mat.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Add-K Smoothening based Bi-Gram Model\n"
      ],
      "metadata": {
        "id": "ddRDnP4nWbKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_K(word_sequence, bigram_counts, unigram_counts, K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+K) / (last_word_unigram_count+K*V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"loyal and\"\n",
        "next_word1 = predict_next_word_bigram_K(sequence1, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"the cat\"\n",
        "next_word2 = predict_next_word_bigram_K(sequence2, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"sat on\"\n",
        "next_word3 = predict_next_word_bigram_K(sequence3, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"computers understand\"\n",
        "next_word4 = predict_next_word_bigram_K(sequence4, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD1WBylSWgDz",
        "outputId": "a5b7ad02-d2b8-406d-e122-f40245dd6c4a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of friendly is  0.11538461538461539\n",
            "probability of inventions. is  0.11538461538461539\n",
            "Given sequence: 'loyal and', predicted next word: 'friendly'\n",
            "probability of sat is  0.11538461538461539\n",
            "Given sequence: 'the cat', predicted next word: 'sat'\n",
            "probability of the is  0.11538461538461539\n",
            "Given sequence: 'sat on', predicted next word: 'the'\n",
            "Given sequence: 'computers understand', predicted next word: ''understand' not found in unigram counts. Cannot predict next word.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Tri-Gram Counts with Add - K Smoothening"
      ],
      "metadata": {
        "id": "Oz8Lh6EeWhJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_K(word_sequence, Trigrams_counts, bigram_counts,K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+K) / (last_two_words_bigram_count+K*V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am working\"\n",
        "next_word1 = predict_next_word_trigram_K(sequence1, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_trigram_K(sequence2, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "id": "x26X2CT9WlCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Add-K Smoothening based Tri-Gram Model\n"
      ],
      "metadata": {
        "id": "A7nnoeduWqM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_K(ip_text, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN4ylHh6WtTK",
        "outputId": "0dd357a9-7a1e-460c-a592-32e8f378930c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textloyal friendly\n",
            "probability of animals. is  0.11538461538461539\n",
            "Given sequence: 'loyal friendly', predicted next word: 'animals.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Tri-Gram Counts with Add - K Smoothening"
      ],
      "metadata": {
        "id": "dbJhyU4zhytZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_K(word_sequence, Trigrams_counts, bigram_counts,K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+K) / (last_two_words_bigram_count+K*V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"the cat sat\"\n",
        "next_word1 = predict_next_word_trigram_K(sequence1, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"sat on the\"\n",
        "next_word2 = predict_next_word_trigram_K(sequence2, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5baO96grh1lN",
        "outputId": "c94a69df-ac0c-4af6-fcc7-1edc70158d5a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  on is  0.11538461538461539\n",
            "Given sequence: 'the cat sat', predicted next word: 'on'\n",
            "probability of  mat. is  0.11538461538461539\n",
            "Given sequence: 'sat on the', predicted next word: 'mat.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Add-K Smoothening based Tri-Gram Model"
      ],
      "metadata": {
        "id": "5n2VlkaWh5c8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_K(ip_text, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3iEZQqqh8OE",
        "outputId": "c64246fd-9e79-45bc-9404-2a00b686cbc0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textsat on the \n",
            "probability of  mat. is  0.11538461538461539\n",
            "Given sequence: 'sat on the ', predicted next word: 'mat.'\n"
          ]
        }
      ]
    }
  ]
}